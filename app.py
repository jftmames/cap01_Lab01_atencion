# app.py
# Laboratorio 1: Visualizando el Mecanismo de Atenci贸n
# Libro IA LABS

# --- Importaciones Esenciales ---
# Importamos las librer铆as necesarias.
# streamlit para la interfaz web, transformers para el modelo, torch es el backend,
# y matplotlib/seaborn para la visualizaci贸n.
import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModel
import matplotlib.pyplot as plt
import seaborn as sns

# --- Configuraci贸n de la P谩gina ---
# Damos un t铆tulo y un 铆cono a nuestra p谩gina en el navegador.
st.set_page_config(
    page_title="Visor de Atenci贸n",
    page_icon="",
    layout="wide"
)

# --- Carga del Modelo (con Cach茅) ---
# Esta funci贸n carga el tokenizer y el modelo.
# Usamos el decorador @st.cache_resource de Streamlit para que esta operaci贸n
# (que es muy lenta) solo se ejecute una vez, la primera vez que se carga la app.
# Las siguientes veces, usar谩 la versi贸n en cach茅, haciendo la app mucho m谩s r谩pida.
@st.cache_resource
def load_model():
    """Carga el modelo y el tokenizer de Hugging Face."""
    # Usaremos 'bert-base-uncased', un modelo est谩ndar y vers谩til.
    # 'output_attentions=True' es CRTICO. Le dice al modelo que nos devuelva
    # los pesos de atenci贸n adem谩s de la salida normal.
    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')
    model = AutoModel.from_pretrained('bert-base-uncased', output_attentions=True)
    return tokenizer, model

# --- T铆tulo y Descripci贸n de la App ---
st.title(" Visor del Mecanismo de Atenci贸n en Transformers")
st.write(
    "Esta aplicaci贸n te permite ver c贸mo funciona el mecanismo de 'atenci贸n' dentro de un modelo Transformer (BERT). "
    "Introduce una frase y observa qu茅 palabras le 'prestan atenci贸n' a otras para construir su significado contextual."
)

# --- Carga de los modelos ---
# Llamamos a nuestra funci贸n para tener el tokenizer y el modelo listos.
# Streamlit mostrar谩 un spinner mientras esta operaci贸n se completa.
with st.spinner("Cargando modelo pre-entrenado..."):
    tokenizer, model = load_model()

# --- Interfaz de Usuario ---
st.header("Introduce tu frase")
# Usamos un text_area para que el usuario pueda escribir su texto.
# Le damos una frase de ejemplo para guiarlo.
user_input = st.text_area(
    "Texto a analizar:",
    "The quick brown fox jumps over the lazy dog.",
    height=100
)

# Creamos columnas para poner los selectores de capa y cabeza uno al lado del otro.
col1, col2 = st.columns(2)
# Creamos un slider para que el usuario elija qu茅 capa de atenci贸n visualizar.
# BERT-base tiene 12 capas (de 0 a 11).
layer_to_visualize = col1.slider("Capa de Atenci贸n a Visualizar", 0, 11, 6)
# Y otro para la cabeza de atenci贸n. BERT-base tiene 12 cabezas (de 0 a 11).
head_to_visualize = col2.slider("Cabeza de Atenci贸n a Visualizar", 0, 11, 0)

# El bot贸n que iniciar谩 el an谩lisis.
if st.button("Visualizar Atenci贸n"):
    if user_input:
        # --- Procesamiento del Modelo ---
        # 1. Tokenizaci贸n: Convertimos el texto en tokens que el modelo entiende.
        inputs = tokenizer(user_input, return_tensors='pt', add_special_tokens=True)
        token_list = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])

        # 2. Inferencia: Pasamos los tokens por el modelo.
        # 'torch.no_grad()' desactiva el c谩lculo de gradientes, lo que acelera
        # la inferencia ya que no estamos entrenando el modelo.
        with torch.no_grad():
            outputs = model(**inputs)

        # 3. Extracci贸n de Atenci贸n:
        # Los pesos de atenci贸n est谩n en 'outputs.attentions'.
        # Es una tupla con las matrices de atenci贸n de cada capa.
        # Seleccionamos la capa y la cabeza que el usuario eligi贸.
        attention_matrix = outputs.attentions[layer_to_visualize][0, head_to_visualize].numpy()

        # --- Visualizaci贸n del Heatmap ---
        st.header(f"Mapa de Calor de Atenci贸n (Capa {layer_to_visualize}, Cabeza {head_to_visualize})")
        st.write(
            "Este mapa muestra la puntuaci贸n de atenci贸n de cada palabra (eje Y) hacia cada otra palabra (eje X). "
            "Un color m谩s brillante significa una puntuaci贸n de atenci贸n m谩s alta."
        )

        # Usamos matplotlib y seaborn para crear el gr谩fico.
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(attention_matrix, xticklabels=token_list, yticklabels=token_list, cmap='viridis', ax=ax)
        plt.xticks(rotation=45) # Rotamos las etiquetas para que no se superpongan.
        ax.set_xlabel("Palabra a la que se 'presta atenci贸n' (Key)")
        ax.set_ylabel("Palabra que 'presta atenci贸n' (Query)")

        # Mostramos el gr谩fico en Streamlit.
        st.pyplot(fig)
    else:
        st.warning("Por favor, introduce una frase para analizar.")
